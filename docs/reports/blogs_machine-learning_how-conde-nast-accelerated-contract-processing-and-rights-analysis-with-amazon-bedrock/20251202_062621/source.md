# How Condé Nast accelerated contract processing and rights analysis with Amazon Bedrock

by Bob Boiko, Christopher Donnellan, Sarat Tatavarthi, Andrei Ivanovic, Enjeh Anyangwe, and Alok Singh on 26 NOV 2025 in Amazon Bedrock, Amazon SageMaker AI, Artificial Intelligence, Customer Solutions, Intermediate (200) Permalink  Comments   Share

*This post is co-written with Bob Boiko, Christopher Donnellan, and Sarat Tatavarthi from Condé Nast.*

For over a century, [Condé Nast](https://www.condenast.com/) has stood at the forefront of global media, shaping culture and conversation through its prestigious portfolio of brands. Founded in 1909, the company has evolved from a traditional publisher into a modern media powerhouse. Today, Condé Nast’s influential brands, including Vogue, The New Yorker, GQ, and Vanity Fair, reach an audience of 72 million readers in print, 394 million digital consumers, and 454 million followers across social networks, making it one of the world’s most influential content creators and distributors.

The company’s extensive portfolio, spanning multiple brands and geographies, required managing an increasingly complex web of contracts, rights, and licensing agreements. The existing process relied heavily on manual review of newly ingested contracts, particularly during strategic initiatives such as brand acquisitions or expansions. Rights management experts spent countless hours identifying and matching incoming contracts to existing templates, extracting granted rights and metadata, and managing licensing agreements for various creative assets, including images, videos, and text content from contributors worldwide. This manual, rule-based approach created significant operational bottlenecks. The process was time-consuming and prone to human error. As a result, the company took a conservative approach to utilizing rights, leading to missed revenue opportunities. Condé Nast needed a modern, efficient solution that could automate contract processing while maintaining the highest standards of accuracy and alignment with regulations.

In this post, we explore how Condé Nast used [Amazon Bedrock](https://aws.amazon.com/bedrock) and Anthropic’s Claude to accelerate their contract processing and rights analysis workstreams.

## Solution overview

Collaborating with Condé Nast’s legal and technical teams, AWS developed an automated contract processing solution powered by AWS AI services focused on parsing, comparison, and data visualization—not providing legal advice of its own. The solution uses the following key services:

- [Amazon Simple Storage Service (Amazon S3)](https://aws.amazon.com/s3) – A scalable object storage service used to store incoming contracts, reference templates, and solution outputs.
- [Amazon OpenSearch Serverless](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-overview.html) – An on-demand serverless configuration for [Amazon OpenSearch Service](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/what-is.html) used as a vector store.
- [Amazon Bedrock](https://aws.amazon.com/bedrock) – A fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies through a single API, along with a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. With Amazon Bedrock, you can experiment with and evaluate top FMs for your use case, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources.
- [AWS Step Functions](https://aws.amazon.com/step-functions/) – A visual workflow service that helps developers use AWS services to build distributed applications, automate processes, orchestrate microservices, and create data and machine learning (ML) pipelines.
- [Amazon SageMaker AI](https://aws.amazon.com/sagemaker/) – A fully managed ML service. With SageMaker AI, data scientists and developers can quickly build, train, and deploy ML models into a production-ready hosted environment. It provides a UI experience for running ML workflows that makes SageMaker AI ML tools available across multiple integrated development environments (IDEs).

The key components are shown in the following architecture diagram.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/24/ML-18993-_image-2.jpg)

The workflow consists of the following steps:

1. A user uploads new contracts to an input S3 bucket. The addition of new contracts triggers [Amazon EventBridge](https://aws.amazon.com/eventbridge/), which starts the main Step Functions workflow.
2. An [Amazon SageMaker Processing](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_processing.html) job processes the contracts, converting them from PDFs to digital text files. This step uses the visual reasoning capabilities of [Anthropic’s Claude 3.7 Sonnet](https://aws.amazon.com/blogs/aws/anthropics-claude-3-7-sonnet-the-first-hybrid-reasoning-model-is-now-available-in-amazon-bedrock/) in Amazon Bedrock to perform the transcription from a PDF (converted to an image) into a raw text file. This operation takes into account handwritten notes, strikethroughs, and specialized document formatting (such as single vs. multiple columns) when evaluating the terms of the individual contracts. The preprocessing is also able to handle large, hundred-page documents by dividing it into smaller chunks and repeatedly executing the preceding step. The resulting text file is saved in an S3 bucket to be used as a basis for a suite of existing and future generative AI use cases. Intermediate processed data outputs are governed by the same access restrictions as the raw source data.
3. Using this text file output, a second SageMaker Processing job runs, using Anthropic’s Claude 3.7 Sonnet in Amazon Bedrock to extract a set of pre-specified metadata fields. The large language model (LLM) is provided a schema through a prompt template, consisting of every potential metadata field of interest accompanied by a short description of that field to aid the model in extraction.
4. A third SageMaker Processing job discovers similar existing templates by comparing the text of the incoming contract to the text of possible templates, stored in an Amazon Bedrock knowledge base. Additionally, Anthropic’s Claude 3.7 Sonnet determines key semantic differences from the most similar templates. The results are collated in a spreadsheet, including extracted metadata fields and most similar templates and boilerplates. These results are saved to an S3 bucket. A notification message is sent to the corresponding business and legal staff to review the results. Incoming contracts with low similarity across the templates are sent to a separate S3 bucket to be used in a separate downstream process (further analysis and generation of new templates).
5. A human reviewer validates the results of the system. Using an [AWS Lambda](https://aws.amazon.com/lambda/) function, valid results are then loaded into Condé Nast’s rights and royalties management system. A notification message is sent, indicating the success or failure of the preceding load. The outputs from the solution are used in a suite of downstream processes, integrating with other internal Condé Nast software solutions.
6. The contracts with no close template matches from Step 5 are routed to undergo further analysis.
7. These low similarity contracts are passed into a clustering algorithm and grouped based on the similarity of their text and the rights granted by each contract.
8. A spreadsheet containing assigned cluster labels, similarity scores, contract text, and more is saved to Amazon S3 as well as accompanying interactive visualizations. A human reviewer uses these results to draft new templates to be used in future deals and runs of the solution. The solution can then be rerun for the contracts that might have new corresponding templates uploaded to the knowledge base in Step 4.

## Benefits and results

By using AWS AI services, Condé Nast has significantly improved its rights management operations:

- **Multiple model access** – Amazon Bedrock can provide access to various FMs through a single API.
- **Seamless integration** – The Amazon Bedrock SDK works effortlessly with SageMaker Processing.
- **Dramatic efficiency gains** – Processing time for contract analysis has been reduced from weeks to hours, enabling faster content deployment and more agile industry responses. This helps rights management experts focus on complex cases and strategic initiatives.
- **Enhanced knowledge accessibility and user empowerment** – The solution has systematized the contract analysis process, dramatically improving access to rights management expertise across the organization. Legal assistants and rights experts can now use their knowledge more efficiently by encoding their expertise into prompts that address routine queries, helping them focus on complex strategic matters while maintaining high accuracy standards.
- **Scalability and flexibility** – The system effortlessly handles increased workloads during high-volume periods, such as major brand acquisitions or expansions, without requiring additional human resources. This facilitates more consistent processing times even during peak demands.
- **Improved accuracy** – The generative AI-powered system’s thorough analysis of contracts and identification of subtle variations has significantly reduced the risk of rights violations and potential legal challenges. This provides Condé Nast with greater confidence in content deployment decisions and better protection of intellectual property assets.
- **Collateral improvements** – The system’s implementation has generated valuable byproducts and learnings that extend beyond its primary function. These insights have supported the development of additional solutions, including a system that translates complex rights availability information into plain language for non-technical users, expanding the utility of rights management across the organization.

## Lessons learned

The implementation of this solution at Condé Nast yielded several key insights, offering valuable lessons for similar digital transformation initiatives in the media industry and beyond:

- **Data preprocessing is foundational** – The team discovered that the quality of metadata extraction and subsequent processes heavily depended on the initial contract processing pipeline. This resulted in the development of an advanced OCR system capable of handling diverse document types, including those with handwritten notes, scanned copies, and multi-column PDFs. Additionally, the system needed to efficiently process large files, both in terms of file size and page count. Without this sophisticated preprocessing capability, the performance of subsequent steps in the workflow would have been severely compromised.
- **Human oversight remains key** – The project reinforced the value of human expertise, particularly for complex data processing tasks. The team found that human evaluation was essential for handling nuanced cases and providing a vital feedback loop for prompt engineering. This human-in-the-loop approach allowed for continuous refinement of the AI models, improving their accuracy and relevance over time. It highlighted the importance of viewing AI as a tool to augment human intelligence rather than replace it entirely.
- **Business-centric approach to technology integration** – A key factor in the project’s success was its focus on solving specific business problems. The team concentrated on how various generative AI/ML solutions could be effectively combined to address Condé Nast’s unique challenges in rights management. This approach made sure the technological solution remained tightly aligned with business objectives, resulting in a more practical and immediately valuable implementation.
- **Early stakeholder alignment** – Involving all relevant parties (legal teams, rights management experts, and technical staff) from the project’s inception proved important. This collaborative approach made sure the solution met compliance requirements while delivering operational efficiency, facilitating smoother adoption across the organization.
- **Incremental implementation** – The decision to roll out the solution incrementally, starting with a subset of contracts for specific brands, allowed for rapid iteration and refinement. This phased approach helped the team gather real-world feedback and make necessary adjustments before full-scale deployment, leading to a more robust and effective solution.
- **Quality of reference data** – The project underscored the importance of diverse, high-quality example documents. The system’s accuracy improved significantly when provided with a comprehensive set of representative historical contracts spanning multiple brands and geographies, highlighting the value of maintaining well-documented contract archives for context and pattern matching.

## Conclusion

Through this collaboration with AWS, Condé Nast has successfully modernized its rights management workflow, creating a more efficient, accurate, and scalable system. The solution addresses immediate operational challenges and positions Condé Nast for future growth by establishing a foundation for AI-driven content management. This implementation serves as a blueprint for how traditional media companies can embrace AI technologies to streamline operations while maintaining the highest standards of rights management and alignment with regulations. The successful deployment of this solution demonstrates the potential of AWS AI/ML services in modernizing traditional contract analysis business processes, setting new standards for efficiency and accuracy in media rights management.

The development of this project is also transforming Condé Nast’s approach to software development, particularly for generative AI applications. By helping subject matter experts drive development through prompt engineering, the organization discovered a more direct and business-aligned path to creating technical solutions. This new model helps experts express requirements in plain English directly to language models, significantly reducing traditional development complexity while improving the accuracy and relevance of outcomes. The shift has redefined how Condé Nast approaches technical innovation, moving from conventional software development cycles to a more dynamic, expertise-driven process.

---

### About the authors

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/25/bob.jpeg)**Bob Boiko** is a Senior Principal Architect at Condé Nast, where he helps chart the future of their content systems. Prior to Condé Nast, Bob founded three content systems companies and served as a Teaching Professor at the University of Washington Information School. Recognized world-wide as a leader in the field of content management, he has well over 20 years of experience designing and building state-of-the-art information systems for top technology corporations (including Microsoft, Motorola, and Boeing). Bob has sat on many advisory boards and is the recipient of many awards including the 2005 EContent 100 Award for leadership in the content management industry. He is author of “Content Management Bible,” “Laughing at the CIO: A parable and Prescription for IT Leadership” and the science fiction novel “The Last Chameleon.” He is internationally known for his lectures and workshops and is a very skilled analyst, facilitator, teacher, designer, and architect with extensive expertise in content and information management systems, software development, User experience and metadata systems.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/25/christopher.jpeg)**Christopher Donnellan** brings over 30 years of experience in publishing and media, specializing in intellectual property, contract negotiation, licensing, and global rights management. Upon joining Condé Nast in 2002, he was tasked with developing scalable systems for rights clearance and contributor agreements in order to facilitate content sharing across international editions. Currently, he leads a global team from Asia to the Americas, focusing on content licensing, global syndication, rights management, and AI-driven contract workflows, aligning with Condé Nast’s evolution into a 21st-century media company. Outside of work, Christopher enjoys checking off bucket list travel destinations, playing tennis, reading, and spending time with his husband, Richard, and their Miniature Schnauzer, Zelda, who makes it clear that she runs the household.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/25/sarat.jpeg)**Sarat Tatavarthi** serves as the Director of Engineering at Condé Nast, where he leads high-performing teams in the design and delivery of distributed web and mobile applications. Beyond his professional role, Sarat is a passionate traveler who enjoys discovering new countries and cultures together with his family.

**![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/25/alok-singh.jpeg)****Alok Singh** is a Senior Machine Learning Engineer at AWS with more than 11 years of experience in artificial intelligence and machine learning. He specializes in helping AWS customers design and deploy AI/ML workloads and solutions on AWS. For the past 3 years, he has been focused on enabling customers to deploy generative AI solutions at scale. He holds a Master of Science in Data Science and a Bachelor of Science in Electronics and Telecommunications.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/25/andrei.jpeg)**Andrei Ivanovic** is a Data Scientist with AWS Professional Services, with experience delivering internal and external solutions across generative AI, computer vision, ML, time series forecasting, and geospatial data science. Andrei has a Master’s in CS from the University of Toronto, where he was a researcher at the intersection of deep learning, robotics, and autonomous driving. Outside of work, he enjoys literature, film, strength training, and spending time with loved ones.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/25/enjeh.jpeg)**Enjeh Anyangwe** is a Technical Engagement Manager at AWS Professional Services, leading strategic customer transformations and developing enterprise delivery frameworks. She specializes in managing complex AWS programs, directing cross-functional teams, and establishing technical delivery strategies in regulated industries. Her work spans project management leadership in AI/ML implementations, migration, data modernization, and M&A technology integration for Fortune 500 companies. She collaborates with AWS field sales, pre- sales, and support teams to drive customer adoption of AWS services. Enjeh holds an MBA from the University of Connecticut Business School with focus in Operations & IT Management. Outside of work, Enjeh enjoys traveling, exploring new cultures, and spending quality time with loved ones.